{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputEmbeddings(\n",
      "  (embedding): Embedding(5, 6)\n",
      ")\n",
      "torch.Size([1, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 6]),\n",
       " tensor([[[-0.4121,  0.0757, -0.6342, -2.1711,  0.3468,  1.4517],\n",
       "          [-0.1795,  0.0305, -0.8155, -0.5573,  0.0734,  0.3309],\n",
       "          [ 1.6115, -1.4192, -0.5432, -2.9637,  0.1750, -1.2888],\n",
       "          [ 0.0209, -0.1609,  1.0488, -0.9283,  0.2751, -0.1187],\n",
       "          [ 0.0209, -0.1609,  1.0488, -0.9283,  0.2751, -0.1187]]],\n",
       "        grad_fn=<EmbeddingBackward0>))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we;ll be building input embeddings\n",
    "# allows to convert token into embedding of dim 1x52  : token -> input ID(position in vocab) ->embedding\n",
    "\n",
    "\n",
    "class InputEmbeddings(nn.Module):\n",
    "    def __init__(self, d_model: int, vocab_size: int):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            d_model (int): dim of vector\n",
    "            vocab_size (int): # of words in vocab\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_embeddings = InputEmbeddings(d_model=6, vocab_size=1000)\n",
    "print(positional)\n",
    "# Create an example input tensor (batch size 1, sequence length 5, embedding dimension 20)\n",
    "batch_of_sentences = torch.tensor([[5, 6, 7, 0, 0]])  # Shape: (batch_size, max_sentence_length)\n",
    "print(batch_of_sentences.shape)\n",
    "\n",
    "\n",
    "# Pass through the embedding layer\n",
    "# The forward method is called automatically when you use the instance like a function.\n",
    "embedded_sentences = input_embeddings(batch_of_sentences)\n",
    "embedded_sentences.shape, embedded_sentences  # (batch, seq_len, embedding dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(5, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "d_model = 6\n",
    "nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## positional encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input  tensor([[[-0.4121,  0.0757, -0.6342, -2.1711,  0.3468,  1.4517],\n",
      "         [-0.1795,  0.0305, -0.8155, -0.5573,  0.0734,  0.3309],\n",
      "         [ 1.6115, -1.4192, -0.5432, -2.9637,  0.1750, -1.2888],\n",
      "         [ 0.0209, -0.1609,  1.0488, -0.9283,  0.2751, -0.1187],\n",
      "         [ 0.0209, -0.1609,  1.0488, -0.9283,  0.2751, -0.1187]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "input shape torch.Size([1, 5, 6])\n",
      "output shape torch.Size([1, 5, 6])\n",
      "tensor([[[-0.8241,  2.1514, -0.0000, -2.3423,  0.0000,  0.0000],\n",
      "         [ 0.0000,  1.1417, -1.5383,  0.8833,  0.0000,  2.6618],\n",
      "         [ 5.0416, -3.6708, -0.9010, -0.0000,  0.0000, -0.5776],\n",
      "         [ 0.0000, -0.0000,  0.0000,  0.1241,  0.5631,  0.0000],\n",
      "         [-0.0000, -0.0000,  0.0000,  0.1091,  0.5674,  1.7626]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n",
    "        \"\"\"\n",
    "                Since our model contains no recurrence and no convolution, in order for the model to make use of the\n",
    "        order of the sequence, we must inject some information about the relative or absolute position of the\n",
    "        tokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\n",
    "        bottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\n",
    "        as the embeddings, so that the two can be summed. There are many choices of positional encodings,\n",
    "        learned and fixed [9].\n",
    "        In this work, we use sine and cosine functions of different frequencies:\n",
    "            `PE(pos,2i) = sin(pos/(10000)**2i/dmodel)`\n",
    "            `PE(pos,2i+1) = cos(pos/(10000)**2i/dmodel)`\n",
    "        where pos is the position and i is the dimension. That is, each dimension of the positional encoding\n",
    "        corresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\n",
    "        chose this function because we hypothesized it would allow the model to easily learn to attend by\n",
    "        relative positions, since for any fixed offset k, P E(pos+k) can be represented as a linear function of\n",
    "        PE(pos).\n",
    "\n",
    "        Keyword arguments:\n",
    "        dropout -- to make model less overfit\n",
    "        seq_len -- Specifies the maximum length of sequence that the model can handle. This helps determine the scale and range of the positional encodings.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # positional encodeing shape: seq_len X d_model i.e. each token will be represented (1*d_model) vector\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        formula :`PE(pos,2i) = cos(pos/(10000)**2i/dmodel) for i=1,3,5, ...and `PE(pos,2i) = sin(pos/(10000)**2i/dmodel) for i=2,4,6, ...and `\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        #  Create a model of shape (seq_len , d_model)\n",
    "\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        #  create a vector of shape(seq_len,1) to represent position of word in sequence\n",
    "\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)  # (seq_len,1)  # pos in formula\n",
    "        # create denominator of formula\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        # apply sin to even positions\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "\n",
    "        # apply cos to odd positions\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # now we need to add batch dimension to these sentences so we can apply it to whole sentences, so to all the batch of sentence, because weill have batch of sentences.\n",
    "        # adding batch dim\n",
    "        pe = pe.unsqueeze(0)  # (1, seq_len, d_model)\n",
    "\n",
    "        # register this tensor in buffer of module  .. it is done for the tensor that you want to keep inside the module, not as a lerarned parameter but you want it to be saved when you save the file of the model\n",
    "        # you should register it as a buffer. this way the tensor would be saved in file along with state of model\n",
    "        self.register_buffer(\"pe\", pe)  # This is typically used to register a buffer that should not to be considered a model parameter.\n",
    "        \"\"\"\n",
    "        Say you have a linear layer nn.Linear. You already have weight and bias parameters. But if you need a new parameter you use register_parameter() to register a new named parameter that is a tensor.\n",
    "        When you register a new parameter it will appear inside the module.parameters() iterator, but when you register a buffer it will not.\n",
    "        The difference:\n",
    "        Buffers are named tensors that do not update gradients at every step, like parameters. For buffers, you create your custom logic (fully up to you).\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        we need to add positional encoding to every token/word inside sequence/sentence\n",
    "        \"\"\"\n",
    "        x = x + (self.pe[:, : x.shape[1], :]).requires_grad_(False)  # x:token and pe is positional encoding  # because we dont want to learn pe because these are fixed\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "positional = PositionalEncoding(d_model=6, seq_len=5, dropout=0.5)\n",
    "\n",
    "# Create an example input tensor (batch size , sequence length , embedding dimension )\n",
    "\n",
    "# Apply positional encoding\n",
    "output_tensor = positional(embedded_sentences)\n",
    "print(\"input \", embedded_sentences)\n",
    "\n",
    "print(\"input shape\", embedded_sentences.shape)\n",
    "print(\"output shape\", output_tensor.shape)\n",
    "\n",
    "print(output_tensor)  # (1, seq_len,d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### register_buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModule()\n",
      "Buffer tensor:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "Another buffer tensor:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "\n",
    "        # Register a buffer tensor with zeros\n",
    "        self.register_buffer(\"buffer_tensor\", torch.zeros(3, 3))\n",
    "\n",
    "        # Register another buffer tensor with specific values\n",
    "        data = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float32)\n",
    "        self.register_buffer(\"another_buffer\", data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the buffer tensors in the forward pass\n",
    "        output = x + self.buffer_tensor\n",
    "        return output\n",
    "\n",
    "\n",
    "# Create an instance of MyModule\n",
    "model = MyModule()\n",
    "\n",
    "# Print the module to see its structure\n",
    "print(model)\n",
    "\n",
    "# Accessing the buffer tensors\n",
    "print(\"Buffer tensor:\")\n",
    "print(model.buffer_tensor)\n",
    "\n",
    "print(\"\\nAnother buffer tensor:\")\n",
    "print(model.another_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noManEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
